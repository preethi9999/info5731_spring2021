{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPyD5KXKKMh+tpASliMXmOi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/preethi9999/info5731_spring2021/blob/main/somaraju_inclassexercise9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXLg0k3BqJn7"
      },
      "source": [
        "The purpose of the exercise is to practice different machine learning algorithms for text classification as well as the performance evaluation. In addition, you are requried to conduct 10 fold cross validation (https://scikit-learn.org/stable/modules/cross_validation.html) in the training.\n",
        "\n",
        "The dataset can be download from here: https://github.com/unt-iialab/info5731_spring2021/blob/main/class_exercises/exercise09_datacollection.zip. The dataset contains two files train data and test data for sentiment analysis in IMDB review, it has two categories: 1 represents positive and 0 represents negative. You need to split the training data into training and validate data (80% for training and 20% for validation, https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6) and perform 10 fold cross validation while training the classifier. The final trained model was final evaluated on the test data.\n",
        "\n",
        "Algorithms:\n",
        "\n",
        "(1) MultinominalNB\n",
        "\n",
        "(2) SVM\n",
        "\n",
        "(3) KNN\n",
        "\n",
        "(4) Decision tree\n",
        "\n",
        "(5) Random Forest\n",
        "\n",
        "(6) XGBoost\n",
        "\n",
        "Evaluation measurement:\n",
        "\n",
        "(1) Accuracy\n",
        "\n",
        "(2) Recall\n",
        "\n",
        "(3) Precison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ehUhK_Gn7pn"
      },
      "source": [
        "#Importing the required libraries\n",
        "\n",
        "import pandas as pd \n",
        "import re \n",
        "import nltk \n",
        "import numpy\n",
        "from nltk.corpus import stopwords \n",
        "from nltk.stem.porter import PorterStemmer \n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import tree"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xB_N2BseqHRk"
      },
      "source": [
        "#we are loading the train and test data\n",
        "\n",
        "data_train=pd.read_fwf(\"/content/sample_data/stsa-train.txt\", header=None)\n",
        "data_train=pd.DataFrame(data_train)\n",
        "data_test=pd.read_fwf(\"/content/sample_data/stsa-test.txt\", header=None)\n",
        "data_test= pd.DataFrame(data_test)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b90fr4O6qHdv"
      },
      "source": [
        "#splitting the train data into training and validation data\n",
        "\n",
        "del data_train[2]\n",
        "data_train = data_train.rename(columns={0: \"Review\", 1: \"Text\"})\n",
        "del data_test[2]\n",
        "del data_test[3]\n",
        "data_test = data_test.rename(columns={0: \"Review\", 1: \"Text\"})\n",
        "x_train, x_validate, y_train, y_validate = sklearn.model_selection.train_test_split(data_train['Text'], data_train['Review'], train_size=0.8, test_size=0.2)\n",
        "x_train = x_train.to_numpy()\n",
        "y_train = y_train.to_numpy()"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxOFMiLdqHlx"
      },
      "source": [
        "#Defining Kfold = 10\n",
        "\n",
        "my_kf = KFold(n_splits=10)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJglxc2E3kAt"
      },
      "source": [
        "*Analysis of various algorithms*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIz7G6FxqHoe"
      },
      "source": [
        "#MultinominalNB\n",
        "\n",
        "pln = Pipeline([('vect', CountVectorizer()),\n",
        "                     ('tfidf', TfidfTransformer()),\n",
        "                     ('clf', MultinomialNB())])\n",
        "for train_index, test_index in my_kf.split(x_train, y_train):\n",
        "    x_train_k, y_train_k = x_train[train_index], y_train[train_index]\n",
        "    x_test_k, y_test_k = x_train[test_index], y_train[test_index]\n",
        "    MNB_algorithm = pln.fit(x_train_k, y_train_k)\n",
        "pred_validate = MNB_algorithm.predict(x_validate)\n",
        "validation = {'Actual value': y_validate, 'Predicted value': pred_validate}\n",
        "validation_df = pd.DataFrame(validation, columns = ['Actual value', 'Predicted value'])"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JX8PkInpqHrA",
        "outputId": "21558040-db0e-43d1-dc3d-55783533f648"
      },
      "source": [
        "#Evaluating MultinominalNB and getting values\n",
        "\n",
        "final = MNB_algorithm.predict(data_test['Text'])\n",
        "print('Accuracy of MultinomialNB:', (accuracy_score(data_test['Review'], final)*100))\n",
        "print('Precision of MultinomialNB:', (accuracy_score(data_test['Review'], final)*100))\n",
        "print('Recall of MultinomialNB:', (recall_score(data_test['Review'], final)*100))\n",
        "print('F1-score of MultinomialNB:', (f1_score(data_test['Review'], final, average='macro')*100))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of MultinomialNB: 81.10928061504667\n",
            "Precision of MultinomialNB: 81.10928061504667\n",
            "Recall of MultinomialNB: 88.66886688668868\n",
            "F1-score of MultinomialNB: 81.00488323181159\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsEuSU_MqHtr"
      },
      "source": [
        "#SVM:\n",
        "\n",
        "pln = Pipeline([('vect', CountVectorizer()),\n",
        "                     ('tfidf', TfidfTransformer()),\n",
        "                     ('clf', LinearSVC())])\n",
        "for train_index, test_index in my_kf.split(x_train, y_train):\n",
        "    x_train_k, y_train_k = x_train[train_index], y_train[train_index]\n",
        "    x_test_k, y_test_k = x_train[test_index], y_train[test_index]\n",
        "    SVM_algorithm = pln.fit(x_train_k, y_train_k)\n",
        "pred_validate = SVM_algorithm.predict(x_validate)\n",
        "validation = {'Actual value': y_validate, 'Predicted value': pred_validate}\n",
        "validation_df = pd.DataFrame(validation, columns = ['Actual value', 'Predicted value'])"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MomhE5xqHwJ",
        "outputId": "ecc495a1-e7e4-40cb-fb73-639095b91de8"
      },
      "source": [
        "#Evaluating SVM and getting values\n",
        "\n",
        "final = SVM_algorithm.predict(data_test['Text'])\n",
        "print('Accuracy of SVM :', (accuracy_score(data_test['Review'], final)*100))\n",
        "print('Precision of SVM :', (accuracy_score(data_test['Review'], final)*100))\n",
        "print('Recall of SVM :', (recall_score(data_test['Review'], final)*100))\n",
        "print('F1-score of SVM :', (f1_score(data_test['Review'], final, average='macro')*100))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of SVM : 80.23064250411862\n",
            "Precision of SVM : 80.23064250411862\n",
            "Recall of SVM : 80.52805280528052\n",
            "F1-score of SVM : 80.23058884835852\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0cRkkZUqHyp"
      },
      "source": [
        "#Decision Tree\n",
        "\n",
        "pln = Pipeline([('vect', CountVectorizer()),\n",
        "                     ('tfidf', TfidfTransformer()),\n",
        "                     ('clf', tree.DecisionTreeClassifier())])\n",
        "for train_index, test_index in my_kf.split(x_train, y_train):\n",
        "    x_train_k, y_train_k = x_train[train_index], y_train[train_index]\n",
        "    x_test_k, y_test_k = x_train[test_index], y_train[test_index]\n",
        "    DT_algorithm = pln.fit(x_train_k, y_train_k)\n",
        "pred_validate = DT_algorithm.predict(x_validate)\n",
        "validation = {'Actual value': y_validate, 'Predicted value': pred_validate}\n",
        "validation_df = pd.DataFrame(validation, columns = ['Actual value', 'Predicted value'])"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ix1yZrvUqH1B",
        "outputId": "a3a2e03a-56d7-4fb2-a5dd-fe50efedd993"
      },
      "source": [
        "#Evaluating Decision tree and getting values\n",
        "\n",
        "final = DT_algorithm.predict(data_test['Text'])\n",
        "print('Accuracy of Decision Tree :', (accuracy_score(data_test['Review'], final)*100))\n",
        "print('Precision of Decision Tree :', (accuracy_score(data_test['Review'], final)*100))\n",
        "print('Recall of Decision Tree :', (recall_score(data_test['Review'], final)*100))\n",
        "print('F1-score of Decision Tree :', (f1_score(data_test['Review'], final, average='macro')*100))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Decision Tree : 61.44975288303131\n",
            "Precision of Decision Tree : 61.44975288303131\n",
            "Recall of Decision Tree : 67.32673267326733\n",
            "F1-score of Decision Tree : 61.32115548003399\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uaz1PUvVqH3l"
      },
      "source": [
        "#KNN\n",
        "\n",
        "pln = Pipeline([('vect', CountVectorizer()),\n",
        "                     ('tfidf', TfidfTransformer()),\n",
        "                     ('clf', KNeighborsClassifier())])\n",
        "for train_index, test_index in my_kf.split(x_train, y_train):\n",
        "    x_train_k, y_train_k = x_train[train_index], y_train[train_index]\n",
        "    x_test_k, y_test_k = x_train[test_index], y_train[test_index]\n",
        "    KNN_algorithm = pln.fit(x_train_k, y_train_k)\n",
        "pred_validate = KNN_algorithm.predict(x_validate)\n",
        "validation = {'Actual value': y_validate, 'Predicted value': pred_validate}\n",
        "validation_df = pd.DataFrame(validation, columns = ['Actual value', 'Predicted value'])"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Unjt6ENyIl8",
        "outputId": "6824b0ff-c3c4-492e-d688-d343e9faf074"
      },
      "source": [
        "#Evaluating KNN and getting values\n",
        "\n",
        "my_final = KNN_algorithm.predict(data_test['Text'])\n",
        "print('Accuracy of KNN :', (accuracy_score(data_test['Review'], final)*100))\n",
        "print('Precision of KNN :', (accuracy_score(data_test['Review'], final)*100))\n",
        "print('Recall of KNN :', (recall_score(data_test['Review'], final)*100))\n",
        "print('F1-score of KNN :', (f1_score(data_test['Review'], final, average='macro')*100))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of KNN : 61.44975288303131\n",
            "Precision of KNN : 61.44975288303131\n",
            "Recall of KNN : 67.32673267326733\n",
            "F1-score of KNN : 61.32115548003399\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WusiSYg-yI0T"
      },
      "source": [
        "#Random Forest\n",
        "\n",
        "pln = Pipeline([('vect', CountVectorizer()),\n",
        "                     ('tfidf', TfidfTransformer()),\n",
        "                     ('clf', RandomForestClassifier(n_estimators=100))])\n",
        "for train_index, test_index in my_kf.split(x_train, y_train):\n",
        "    x_train_k, y_train_k = x_train[train_index], y_train[train_index]\n",
        "    x_test_k, y_test_k = x_train[test_index], y_train[test_index]\n",
        "    RF_algorithm = pln.fit(x_train_k, y_train_k)\n",
        "pred_validate = RF_algorithm.predict(x_validate)\n",
        "validation = {'Actual value': y_validate, 'Predicted value': pred_validate}\n",
        "validation_df = pd.DataFrame(validation, columns = ['Actual value', 'Predicted value'])"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uldu8jXzyI3Y",
        "outputId": "a67317c8-ee83-481d-fd59-4ca730394463"
      },
      "source": [
        "#Evaluating Random Forest and getting values\n",
        "\n",
        "final = RF_algorithm.predict(data_test['Text'])\n",
        "print('Accuracy of Random Forest :', (accuracy_score(data_test['Review'], final)*100))\n",
        "print('Precision of Random Forest :', (accuracy_score(data_test['Review'], final)*100))\n",
        "print('Recall of Random Forest :', (recall_score(data_test['Review'], final)*100))\n",
        "print('F1-score of Random Forest :', (f1_score(data_test['Review'], final, average='macro')*100))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Random Forest : 71.55409115870401\n",
            "Precision of Random Forest : 71.55409115870401\n",
            "Recall of Random Forest : 76.89768976897689\n",
            "F1-score of Random Forest : 71.47646095452819\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LudPi_oyI6n",
        "outputId": "9fe5e3d9-3acf-47c6-f59b-733eb832b144"
      },
      "source": [
        "#XGBoost\n",
        "\n",
        "pln = Pipeline([('vect', CountVectorizer()),\n",
        "                     ('tfidf', TfidfTransformer()),\n",
        "                     ('clf', GradientBoostingClassifier(n_estimators=20,verbose=2))])\n",
        "for train_index, test_index in my_kf.split(x_train, y_train):\n",
        "    x_train_k, y_train_k = x_train[train_index], y_train[train_index]\n",
        "    x_test_k, y_test_k = x_train[test_index], y_train[test_index]\n",
        "    \n",
        "    XGB_algorithm = pln.fit(x_train_k, y_train_k)\n",
        "pred_validate = XGB_algorithm.predict(x_validate)\n",
        "validation = {'Actual value': y_validate, 'Predicted value': pred_validate}\n",
        "validation_df = pd.DataFrame(validation, columns = ['Actual value', 'Predicted value'])"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.3763            0.61s\n",
            "         2           1.3695            0.58s\n",
            "         3           1.3634            0.53s\n",
            "         4           1.3583            0.50s\n",
            "         5           1.3536            0.46s\n",
            "         6           1.3490            0.43s\n",
            "         7           1.3450            0.41s\n",
            "         8           1.3409            0.39s\n",
            "         9           1.3369            0.35s\n",
            "        10           1.3330            0.32s\n",
            "        11           1.3293            0.30s\n",
            "        12           1.3255            0.26s\n",
            "        13           1.3224            0.23s\n",
            "        14           1.3194            0.20s\n",
            "        15           1.3161            0.16s\n",
            "        16           1.3127            0.13s\n",
            "        17           1.3091            0.10s\n",
            "        18           1.3059            0.07s\n",
            "        19           1.3028            0.03s\n",
            "        20           1.3000            0.00s\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.3755            0.62s\n",
            "         2           1.3685            0.58s\n",
            "         3           1.3621            0.56s\n",
            "         4           1.3563            0.53s\n",
            "         5           1.3513            0.49s\n",
            "         6           1.3469            0.45s\n",
            "         7           1.3429            0.41s\n",
            "         8           1.3382            0.38s\n",
            "         9           1.3337            0.35s\n",
            "        10           1.3300            0.32s\n",
            "        11           1.3257            0.28s\n",
            "        12           1.3224            0.25s\n",
            "        13           1.3191            0.22s\n",
            "        14           1.3155            0.19s\n",
            "        15           1.3118            0.16s\n",
            "        16           1.3091            0.13s\n",
            "        17           1.3059            0.10s\n",
            "        18           1.3032            0.06s\n",
            "        19           1.3005            0.03s\n",
            "        20           1.2978            0.00s\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.3761            0.68s\n",
            "         2           1.3691            0.64s\n",
            "         3           1.3632            0.59s\n",
            "         4           1.3578            0.53s\n",
            "         5           1.3526            0.50s\n",
            "         6           1.3483            0.46s\n",
            "         7           1.3442            0.43s\n",
            "         8           1.3399            0.40s\n",
            "         9           1.3361            0.36s\n",
            "        10           1.3323            0.32s\n",
            "        11           1.3283            0.29s\n",
            "        12           1.3246            0.26s\n",
            "        13           1.3212            0.22s\n",
            "        14           1.3182            0.19s\n",
            "        15           1.3149            0.16s\n",
            "        16           1.3120            0.13s\n",
            "        17           1.3086            0.09s\n",
            "        18           1.3054            0.06s\n",
            "        19           1.3020            0.03s\n",
            "        20           1.2997            0.00s\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.3764            0.62s\n",
            "         2           1.3696            0.62s\n",
            "         3           1.3638            0.57s\n",
            "         4           1.3582            0.53s\n",
            "         5           1.3532            0.49s\n",
            "         6           1.3483            0.45s\n",
            "         7           1.3440            0.42s\n",
            "         8           1.3396            0.39s\n",
            "         9           1.3356            0.35s\n",
            "        10           1.3324            0.32s\n",
            "        11           1.3285            0.29s\n",
            "        12           1.3250            0.25s\n",
            "        13           1.3215            0.22s\n",
            "        14           1.3187            0.19s\n",
            "        15           1.3159            0.16s\n",
            "        16           1.3133            0.13s\n",
            "        17           1.3106            0.09s\n",
            "        18           1.3078            0.06s\n",
            "        19           1.3049            0.03s\n",
            "        20           1.3022            0.00s\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.3758            0.63s\n",
            "         2           1.3688            0.60s\n",
            "         3           1.3627            0.56s\n",
            "         4           1.3572            0.51s\n",
            "         5           1.3520            0.47s\n",
            "         6           1.3472            0.46s\n",
            "         7           1.3421            0.42s\n",
            "         8           1.3380            0.39s\n",
            "         9           1.3340            0.35s\n",
            "        10           1.3305            0.32s\n",
            "        11           1.3267            0.29s\n",
            "        12           1.3226            0.25s\n",
            "        13           1.3200            0.22s\n",
            "        14           1.3169            0.19s\n",
            "        15           1.3140            0.16s\n",
            "        16           1.3111            0.12s\n",
            "        17           1.3080            0.09s\n",
            "        18           1.3055            0.06s\n",
            "        19           1.3028            0.03s\n",
            "        20           1.3003            0.00s\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.3752            0.62s\n",
            "         2           1.3683            0.58s\n",
            "         3           1.3625            0.55s\n",
            "         4           1.3572            0.51s\n",
            "         5           1.3524            0.47s\n",
            "         6           1.3482            0.43s\n",
            "         7           1.3441            0.41s\n",
            "         8           1.3403            0.37s\n",
            "         9           1.3360            0.34s\n",
            "        10           1.3319            0.31s\n",
            "        11           1.3286            0.28s\n",
            "        12           1.3250            0.25s\n",
            "        13           1.3211            0.22s\n",
            "        14           1.3179            0.19s\n",
            "        15           1.3147            0.16s\n",
            "        16           1.3123            0.13s\n",
            "        17           1.3099            0.09s\n",
            "        18           1.3067            0.06s\n",
            "        19           1.3040            0.03s\n",
            "        20           1.3009            0.00s\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.3757            0.59s\n",
            "         2           1.3688            0.56s\n",
            "         3           1.3631            0.53s\n",
            "         4           1.3577            0.49s\n",
            "         5           1.3526            0.46s\n",
            "         6           1.3481            0.43s\n",
            "         7           1.3438            0.40s\n",
            "         8           1.3388            0.37s\n",
            "         9           1.3349            0.34s\n",
            "        10           1.3305            0.31s\n",
            "        11           1.3270            0.28s\n",
            "        12           1.3239            0.25s\n",
            "        13           1.3200            0.22s\n",
            "        14           1.3167            0.18s\n",
            "        15           1.3138            0.15s\n",
            "        16           1.3112            0.12s\n",
            "        17           1.3080            0.09s\n",
            "        18           1.3048            0.06s\n",
            "        19           1.3019            0.03s\n",
            "        20           1.2997            0.00s\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.3753            0.59s\n",
            "         2           1.3687            0.57s\n",
            "         3           1.3627            0.55s\n",
            "         4           1.3576            0.51s\n",
            "         5           1.3530            0.48s\n",
            "         6           1.3486            0.44s\n",
            "         7           1.3446            0.41s\n",
            "         8           1.3408            0.38s\n",
            "         9           1.3371            0.34s\n",
            "        10           1.3324            0.31s\n",
            "        11           1.3291            0.28s\n",
            "        12           1.3254            0.25s\n",
            "        13           1.3217            0.22s\n",
            "        14           1.3190            0.19s\n",
            "        15           1.3163            0.16s\n",
            "        16           1.3138            0.12s\n",
            "        17           1.3110            0.09s\n",
            "        18           1.3072            0.06s\n",
            "        19           1.3043            0.03s\n",
            "        20           1.3015            0.00s\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.3765            0.62s\n",
            "         2           1.3697            0.57s\n",
            "         3           1.3637            0.53s\n",
            "         4           1.3581            0.49s\n",
            "         5           1.3534            0.47s\n",
            "         6           1.3489            0.45s\n",
            "         7           1.3443            0.42s\n",
            "         8           1.3402            0.39s\n",
            "         9           1.3366            0.35s\n",
            "        10           1.3328            0.32s\n",
            "        11           1.3290            0.29s\n",
            "        12           1.3257            0.25s\n",
            "        13           1.3218            0.22s\n",
            "        14           1.3187            0.19s\n",
            "        15           1.3155            0.16s\n",
            "        16           1.3132            0.13s\n",
            "        17           1.3098            0.09s\n",
            "        18           1.3071            0.06s\n",
            "        19           1.3040            0.03s\n",
            "        20           1.3009            0.00s\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.3749            0.64s\n",
            "         2           1.3675            0.59s\n",
            "         3           1.3611            0.55s\n",
            "         4           1.3555            0.51s\n",
            "         5           1.3505            0.48s\n",
            "         6           1.3459            0.45s\n",
            "         7           1.3410            0.43s\n",
            "         8           1.3371            0.39s\n",
            "         9           1.3329            0.36s\n",
            "        10           1.3295            0.32s\n",
            "        11           1.3258            0.29s\n",
            "        12           1.3220            0.26s\n",
            "        13           1.3182            0.23s\n",
            "        14           1.3147            0.20s\n",
            "        15           1.3119            0.16s\n",
            "        16           1.3090            0.13s\n",
            "        17           1.3060            0.10s\n",
            "        18           1.3034            0.06s\n",
            "        19           1.2999            0.03s\n",
            "        20           1.2972            0.00s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jfzujv-SyI-M",
        "outputId": "4d22d35a-5626-471d-9ca5-bb9f338c33de"
      },
      "source": [
        "#Evaluating XG Boost and getting values\n",
        "\n",
        "final = XGB_algorithm.predict(data_test['Text'])\n",
        "print('Accuracy of XG Boost :',(accuracy_score(data_test['Review'],final)*100))\n",
        "print('Precision of XG Boost :',(accuracy_score(data_test['Review'], final)*100))\n",
        "print('Recall of XG Boost :',(recall_score(data_test['Review'], final)*100))\n",
        "print('F1-score of XG Boost :',(f1_score(data_test['Review'], final, average='macro')*100))\n"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of XG Boost : 59.30807248764415\n",
            "Precision of XG Boost : 59.30807248764415\n",
            "Recall of XG Boost : 87.12871287128714\n",
            "F1-score of XG Boost : 55.93239767800719\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dhg0W1vayJBZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpM9ItGXqH7E"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}