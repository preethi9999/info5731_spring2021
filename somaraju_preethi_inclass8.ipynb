{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPnqxjT1iMhw/iqZ09DUqGw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/preethi9999/info5731_spring2021/blob/main/somaraju_preethi_inclass8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXeFf2FU0d1b"
      },
      "source": [
        "(1) (10 points) Write a python program to extract the sentiment related terms from the corpus. You may use python package such as polyglot or external lexicon resources in the question. Rank the sentiment related terms by frequency."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LniYyhiB0jwo",
        "outputId": "33653191-1b28-4b2a-a437-fe286b56e811"
      },
      "source": [
        "!pip install pytreebank"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytreebank\n",
            "  Downloading https://files.pythonhosted.org/packages/e0/12/626ead6f6c0a0a9617396796b965961e9dfa5e78b36c17a81ea4c43554b1/pytreebank-0.2.7.tar.gz\n",
            "Building wheels for collected packages: pytreebank\n",
            "  Building wheel for pytreebank (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytreebank: filename=pytreebank-0.2.7-cp37-none-any.whl size=37070 sha256=5abbe8684e140828a3e34aca33f93b145d18e70b85e4a94ba4f2950409853269\n",
            "  Stored in directory: /root/.cache/pip/wheels/e0/b6/91/e9edcdbf464f623628d5c3aa9de28888c726e270b9a29f2368\n",
            "Successfully built pytreebank\n",
            "Installing collected packages: pytreebank\n",
            "Successfully installed pytreebank-0.2.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJKIPegh0j4v",
        "outputId": "4cddf967-7621-4292-8cfd-0c21fb2fdd88"
      },
      "source": [
        "import pytreebank\n",
        "import sys\n",
        "import os\n",
        "path = os.path.join(sys.path[0],'sst_{}.txt')\n",
        "dataset = pytreebank.load_sst('./cleaned_data')\n",
        "for category in ['train', 'test']:\n",
        "    with open(path.format(category), 'w') as outfile:\n",
        "        for item in dataset[category]:\n",
        "            outfile.write(\"__label__{}\\t{}\\n\".format(\n",
        "                item.to_labeled_lines()[0][0] + 1,\n",
        "                item.to_labeled_lines()[0][1]\n",
        "            ))\n",
        "\n",
        "print(len(dataset['train']))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8544\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHxwYLjh0j72",
        "outputId": "831961a7-88c9-4fee-fa53-7396b80a55dd"
      },
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "stop = stopwords.words('english')\n",
        "from textblob import TextBlob\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "RtojuodC0j-p",
        "outputId": "0b5dbd6a-7502-4031-98c5-5c480b4d476c"
      },
      "source": [
        "in_data = pd.read_csv(\"/content/input_8.csv\")\n",
        "in_data = in_data[['Abstract']]\n",
        "in_data['Abstract'] = in_data['Abstract'].str.replace('[^\\w\\s]','')\n",
        "in_data['Abstract'] = in_data['Abstract'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
        "in_data['Abstract'] = in_data['Abstract'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
        "in_data['Abstract'] = in_data['Abstract'].apply(lambda x: nltk.word_tokenize(x))\n",
        "data_freq = (in_data['Abstract']).apply(lambda x: pd.value_counts(x)).sum(axis = 0).reset_index()\n",
        "data_freq.columns = ['words', 'tf value']\n",
        "data_freq['polarity score'] = data_freq['words'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
        "senti_terms = data_freq.loc[data_freq['polarity score'] != 0].sort_values(by='tf value', ascending=False)\n",
        "senti_terms = senti_terms.reset_index(drop=True)\n",
        "print('Ranking sentiment based on frequency:')\n",
        "senti_terms"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ranking sentiment based on frequency:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>words</th>\n",
              "      <th>tf value</th>\n",
              "      <th>polarity score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>natural</td>\n",
              "      <td>71.0</td>\n",
              "      <td>0.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>linguistic</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>new</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.136364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>many</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>effective</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>cultural</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>conventional</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.142857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>contemporary</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.166667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>fit</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>kind</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.600000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>90 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           words  tf value  polarity score\n",
              "0        natural      71.0        0.100000\n",
              "1     linguistic      10.0        0.100000\n",
              "2            new       8.0        0.136364\n",
              "3           many       7.0        0.500000\n",
              "4      effective       7.0        0.600000\n",
              "..           ...       ...             ...\n",
              "85      cultural       1.0        0.100000\n",
              "86  conventional       1.0       -0.142857\n",
              "87  contemporary       1.0        0.166667\n",
              "88           fit       1.0        0.400000\n",
              "89          kind       1.0        0.600000\n",
              "\n",
              "[90 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HSkzUUO0kBd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpCQrUQwTI9Q"
      },
      "source": [
        "(10 points) Compare the performance of the following tools in sentiment identification: TextBlob (https://textblob.readthedocs.io/en/dev/), VADER (https://github.com/cjhutto/vaderSentiment), TFIDF-based Support Vector Machine (SVM) (Split your data into training and testing data). Take your own annotation as the standard answers.\n",
        "\n",
        "Reference code: https://towardsdatascience.com/fine-grained-sentiment-analysis-in-python-part-1-2697bb111ed4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Stn9qs3Q0kEN"
      },
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv(\"/content/sample_data/cleaned_data.csv\",usecols=[\"clean text\",\"sentiment\"])\n",
        "df=df.dropna().reset_index()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "yu_DQH-A0kG-",
        "outputId": "42bd3b07-3a00-4b60-ae57-bb9b9627557f"
      },
      "source": [
        "df"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>clean text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>introduction statistical natural language proc...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>the paper summarizes essential property docume...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>abstract language way communicating word langu...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>we report experiment use standard natural lang...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>paper describe simple rule based approach auto...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>95</td>\n",
              "      <td>bibliography</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>96</td>\n",
              "      <td>applying natural language processing technique...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>97</td>\n",
              "      <td>example natural language chinese english itali...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>98</td>\n",
              "      <td>a number powerful modelling technique develope...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>99</td>\n",
              "      <td>a semi automated approach design database enha...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>97 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    index                                         clean text sentiment\n",
              "0       0  introduction statistical natural language proc...  positive\n",
              "1       1  the paper summarizes essential property docume...  positive\n",
              "2       2  abstract language way communicating word langu...  positive\n",
              "3       3  we report experiment use standard natural lang...  positive\n",
              "4       4  paper describe simple rule based approach auto...  positive\n",
              "..    ...                                                ...       ...\n",
              "92     95                                       bibliography  positive\n",
              "93     96  applying natural language processing technique...  positive\n",
              "94     97  example natural language chinese english itali...  positive\n",
              "95     98  a number powerful modelling technique develope...  positive\n",
              "96     99  a semi automated approach design database enha...  positive\n",
              "\n",
              "[97 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKJTf_9J0kJt",
        "outputId": "1f81d366-393c-4197-e04a-7c5b3a5183a3"
      },
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "textblob_data = pd.read_csv(\"/content/sample_data/final_input.csv\")\n",
        "textblob_data['polarity'] = textblob_data['Abstract'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
        "textblob_data['predicted_sentiment'] = pd.cut(textblob_data['polarity'], bins=4, labels=[1, 2, 3, 4])\n",
        "def sentiment(x):\n",
        "    if x in [1, 2]:\n",
        "        return 'Negative'\n",
        "    if x == 3:\n",
        "        return 'Neutral'\n",
        "    if x == 4:\n",
        "        return 'Positive'\n",
        "textblob_data['predicted_sentiment'] = textblob_data['predicted_sentiment'].apply(lambda x: sentiment(x))\n",
        "textblob_data\n",
        "print(textblob_data[['doc_id','sentiment', 'predicted_sentiment']].head())\n",
        "textblob_accuracy = accuracy_score(textblob_data['sentiment'], textblob_data['predicted_sentiment'])*100\n",
        "textblob_f1 = f1_score(textblob_data['sentiment'], textblob_data['predicted_sentiment'], average='macro')\n",
        "print('accuracy using textBlob:', textblob_accuracy)\n",
        "print('f1score using textBlob:', textblob_f1)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   doc_id sentiment predicted_sentiment\n",
            "0       0  positive             Neutral\n",
            "1       1  positive             Neutral\n",
            "2       2  positive             Neutral\n",
            "3       3  positive             Neutral\n",
            "4       4  positive             Neutral\n",
            "accuracy using textBlob: 0.0\n",
            "f1score using textBlob: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTQmo3GD0kMd",
        "outputId": "0f5de86e-150e-47c5-a408-c827bc637104"
      },
      "source": [
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "vader = SentimentIntensityAnalyzer()\n",
        "vader_data = pd.read_csv(\"/content/sample_data/final_input.csv\")\n",
        "vader_data['polarity'] = textblob_data['Abstract'].apply(lambda x: vader.polarity_scores(x)['compound'])\n",
        "vader_data['predicted_sentiment'] = pd.cut(vader_data['polarity'], bins=4, labels=[1, 2, 3, 4])\n",
        "vader_data['predicted_sentiment'] = vader_data['predicted_sentiment'].apply(lambda x: sentiment(x))\n",
        "print(vader_data[['doc_id', 'sentiment', 'predicted_sentiment']].head())\n",
        "vader_accuracy = accuracy_score(vader_data['sentiment'], vader_data['predicted_sentiment'])*100\n",
        "vader_f1 = f1_score(vader_data['sentiment'], vader_data['predicted_sentiment'], average='macro')\n",
        "print('accuracy using vader sentiment analysis:', vader_accuracy)\n",
        "print('f1score using vader sentiment analysis:', vader_f1)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "   doc_id sentiment predicted_sentiment\n",
            "0       0  positive             Neutral\n",
            "1       1  positive            Positive\n",
            "2       2  positive            Positive\n",
            "3       3  positive            Positive\n",
            "4       4  positive            Negative\n",
            "accuracy using vader sentiment analysis: 0.0\n",
            "f1score using vader sentiment analysis: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "741AL8Zm0kPC",
        "outputId": "a4b55ae9-4887-4b58-accf-c24091030aa4"
      },
      "source": [
        "import sklearn\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "svm_input = pd.read_csv(\"/content/sample_data/final_input.csv\")\n",
        "train, test = sklearn.model_selection.train_test_split(svm_input, train_size=0.6, test_size=0.1)\n",
        "mypip = Pipeline([('vect', CountVectorizer()),\n",
        "                     ('tfidf', TfidfTransformer()),\n",
        "                     ('clf', SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, random_state=42, max_iter=100, \n",
        "                                           learning_rate='optimal', tol=None))])\n",
        "\n",
        "svm = mypip.fit(train['Abstract'], train['sentiment'])\n",
        "test['predicted_sentiment'] = svm.predict(test['Abstract'])\n",
        "print(test[['doc_id', 'sentiment', 'predicted_sentiment']].head())\n",
        "\n",
        "svm_accuracy = accuracy_score(test['sentiment'], test['predicted_sentiment'])*100\n",
        "svm_f1 = f1_score(test['sentiment'], test['predicted_sentiment'], average='macro')\n",
        "\n",
        "print('accuracy using TFIDF-based SVM:', svm_accuracy)\n",
        "print('f1score using TFIDF-based SVM :', svm_f1)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    doc_id sentiment predicted_sentiment\n",
            "72      72   neutral            positive\n",
            "70      70  positive            positive\n",
            "28      28  negative            positive\n",
            "7        7  positive            positive\n",
            "76      76  positive            positive\n",
            "accuracy using TFIDF-based SVM: 70.0\n",
            "f1score using TFIDF-based SVM : 0.27450980392156865\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvAwmBsR0kSZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6oUqyFZv2GZ"
      },
      "source": [
        "Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7LuR9Znv5ve"
      },
      "source": [
        "'''\n",
        "In the above sentiment analysis is performed using below packages\n",
        "\n",
        "Textblob : It is a python library used for textual processing. It provides a simple API for diving into common natural language processing (NLP) tasks \n",
        "such as part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, translation, and more.\n",
        "Textblob returns two properties of input sentence that is polarity and subjectivity.\n",
        "\n",
        "VADER : It is a lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed in social media.\n",
        "Vader uses a combination of A sentiment lexicon is a list of lexical features (e.g., words) which are generally labeled according to their semantic orientation as either positive or negative. \n",
        "Vader not only tells about the Positivity and Negativity score but also tells us about how positive or negative a sentiment is.\n",
        "\n",
        "SVM : Support vector machine (SVM) is a learning technique that performs well on sentiment classification. Tf-IDF lets us know know the importance of word in a document as it relates to frequency.\n",
        "SVM is a supervised machine learning algorithm that can be used for both classification or regression challenges.\n",
        "\n",
        "we can measure the accuracy of model using F1 score/Fscore. A good F1 score means it has low false positives and false negatives and it is near to expected result, where as \n",
        "bad f1 score indicates more of false positives and negatives. With good fscore we can identify the real threats.\n",
        "\n",
        "As per my analysis , we can see that F1 score using SVM is good and accurate compared to other two models.\n",
        "Out of three models SVM is good for sentiment analysis as f1 score and accuracy is low for Text blob and vader methods.\n",
        "\n",
        "'''\n",
        "\n"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e672sZPSv57r"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}